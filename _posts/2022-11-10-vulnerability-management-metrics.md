---
layout: post
description: Vulnerability Management Metrics
comments: true
date: 2022-11-10
last-update: 2022-10-26
---

WiP

---

# What is Vulnerabilty Management

You can find a general definition of Vulnerability Management in many palces, like  [Wikipedia](https://en.wikipedia.org/wiki/Vulnerability_management).
But, for the sake of this document, I am considering the definition adopted by the vast majority of medium and big companies.

For the rest of this note, I am assuming that

> Vulnerability Management is the set of processes and mechanisms used to _manage the risk_ posed to the company by _known software vulnerabilities_.

In this simple statement there are two imporant concepts that determine the scope and goals of this very complicated world: risk management and known vulnerabilities.

We shall see in details what these mean, providing some ideas on how to measure the effectiveness of a Vulnerability Management program.

# Executive metrics

Even though a plethora of metrics can be used to show progress of a Vulnerability Management program, we can identify two _first order_, or executive, metrics: **_Risk and Coverage_**.

The other metrics we are discussing in this document are _leading_ metrics for either Risk or Converge, and can be used to identify bottlenecks and prioritize the work needed to bring risk down or improve coverage.

## Risk

When managing vulnerability at scale, it is crucial to evaluate the realistic risk posed by known vulnerabilities.

Intuitively, remediating a severe vulnerability affecting a _single asset_ should not be more urgent than remediating _many assets_ vulnerable to different vulnerability, with a similar severity score.

### Simple Risk

In its simplest form, Risk can be quantified by the sum of the product of number of affected assets by the Common Vulnerability Scoring System score ([CVSS, as defined by NIST](https://www.first.org/cvss/user-guide)).

The number of affected assets represents the _potential attack surface_, while the score represents the risk posed by the vulnerability on a single software instance.

Formally, we can define the simple Risk ($sRisk$) for a given vulnerability $v$ in the set of known vulnerabilities $V$ as:

$$ sRisk(v) = assets(v) \cdot  cvss(v), v \in V $$

Or, if we want to calculate the aggregated risk on all the software we own:

$$ sRisk = \sum\limits_{v \in V} assets(v) \cdot cvss(v) $$

In both cases, $assets(v)$ is the number of assets (i.e., software instances) affected by the vulnerability $v$, and $cvss(v)$ is the CVSS Score of $v$.

### Triaged Risk

The previous definition does not account for automatic or manual triage, which allows to obtain a score for a given vulnerability in the context of both its actual usage and potential mitigations applied.
Many times, the risk for a software vulnerability is given by how that particular software is compiled, configured and used.

**Automatic triage**
For instance RedHat provides an [adjusted score for RHEL](https://access.redhat.com/security/updates/classification) (RedHat Enterprise Linux) packages. As you can read in their documentation:

> For example, NVD may rate a flaw in a particular service as having High Impact on the CVSS CIA Triad (Confidentiality, Integrity, Availability) where the service in question is typically run as the root user with full privileges on a system. However, in a Red Hat product, the service may be specifically configured to run as a dedicated non-privileged user running entirely in a SELinux sandbox, greatly reducing the immediate impact from compromise, resulting in Low impact.

Other security assessment automated tools, like vulnerability scanners, often try to give a better score, and reduce the number of false positives, by taking into account the context and how the software is used and the mitigations in place (e.g., AppArmor or SeLinux).

**Manual triage**
In environments where there is an high level of "standardization" and customization (e.g., hyper-scale companies), human triage can be also used: security analysts reviews vulnerabilities and manually adjust (up or down) the CVSS score. This is done typically by tweaking the [CVSS vector string](https://www.first.org/cvss/calculator/3.0) according to the context.

For instance, [CVE-2020-12284](https://nvd.nist.gov/vuln/detail/CVE-2020-12284) affects [FFmpg](https://www.ffmpeg.org) 4.1 and 4.2.2, but we know our version is not compiled with anything using `cbs_jpeg_split_fragment` in `libavcodec/cbs_jpeg.c`.
The problem is still there, so it would be nice to have an upgrade asap, but upgrading FFmped is less urgent than an explitable vulnerablity, so we can "temporarily downgrade" the score.
Viceversa, there could be situations in which we might want to bump up the risk score, because a given software is configured in a way that makes the impacts of an exploit even more dangerous...

**Triaged Risk calculation**
We can define the instantaneous triaged Risk, $tRisk$, for a vulnerability $v \in V$, as

$$ tRisk(v) = assets(v) \cdot tscore(v)$$

where $tscore(v)$ is the triage score for $v$. This is a function of the CVSS score and any other automatic and manual assessment regarding $v$.

It is also usful to calculate the aggregated triaged Risk on all the assets (e.g., machines). This can be calculated as follows:

$$ tRisk = \sum\limits_{v \in V} assets(v) \cdot tscore(v) $$
