---
layout: post
description: Vulnerability Management Metrics
comments: true
date: 2022-11-10
last-update: 2022-10-26
---

WiP

I took these metrics because I have been using them to drive vulnerability management at scale in my former job.
In this document I tried to generalize, abstract, and formalize those metrics as much as possible, so that I could discuss whys more hows.

---

# Table of Contents

- [Table of Contents](#table-of-contents)
- [What is Vulnerability Management](#what-is-vulnerability-management)
- [Executive metrics](#executive-metrics)
  - [Risk](#risk)
    - [Simple Risk](#simple-risk)
    - [Triaged Risk](#triaged-risk)
    - [Enhanced Risk](#enhanced-risk)
    - [Normalizing the Risk](#normalizing-the-risk)
    - [Defining what good looks like for Risk](#defining-what-good-looks-like-for-risk)
  - [Coverage](#coverage)
    - [Inventory Coverage](#inventory-coverage)
    - [Coverage Confidence](#coverage-confidence)
    - [Defining what good looks like for Coverage](#defining-what-good-looks-like-for-coverage)
- [Operational Metrics](#operational-metrics)
  - [Remediation Timeliness](#remediation-timeliness)
    - [Average Vulnerabilities Age](#average-vulnerabilities-age)
    - [Time To Manage](#time-to-manage)
    - [Defining what good looks like for Remediation Timeliness](#defining-what-good-looks-like-for-remediation-timeliness)
  - [Remediation queue size](#remediation-queue-size)
  - [Assets freshness](#assets-freshness)

# What is Vulnerability Management

You can find a general definition of Vulnerability Management in many places, like [Wikipedia](https://en.wikipedia.org/wiki/Vulnerability_management).
But, for the sake of this document, I am considering the definition adopted by the vast majority of medium and large companies.

For the rest of this note, I am assuming that:

> Vulnerability Management is the set of processes and mechanisms used to _manage the risk_ posed to the company by _known software vulnerabilities_.

In this simple statement, there are two important concepts that determine the scope and goals of this very complicated world: risk management and known vulnerabilities.

We shall see in details what these mean, providing some ideas on how to measure the effectiveness of a Vulnerability Management program.

# Executive metrics

Running a Vulnerability Management program is expensive. So, if you want to make sure what you are doing is efficient, you need effective metrics.

Even though a plethora of metrics can be used, you want to tell at a glance where you are and your progress. Moreover, you definitely don't want to drown in an ocean of graphs and numbers or present your VP the details about how you run things.

We can identify two _first order_, or _executive_, metrics: **_Risk and Coverage_**.

In this document, we will be discussing these two metrics first. Then we will explore _second order_, or _operational_, metrics that we can define also as _leading_ metrics for either Risk or Converge. These can be used to identify bottlenecks and prioritize the work needed to bring Risk down or improve Coverage.

## Risk

When managing vulnerabilities at scale, it is crucial to evaluate the realistic risk posed by known vulnerabilities.

With Risk, we want to have an idea of how easy it would be for an attacker to leverage vulnerabilities on our software assets to damage the company.
In the diverse and ample spectrum of the possible damages a company can get from security incidents, are stealing of trade secrets, user data compromise, or image damage which can just be caused by exposing a bad management of security...

So, we want to make sure we consider all known vulnerabilities, along with the likelihood and the impact of them being exploited.

It is impractical for the typical attacker to enumerate all the possible vulnerabilities to find the "perfect one". A widespread vulnerability will be easier to spot.

Another important reason why you should adopt a Risk metric is prioritization of remediation. When dealing with security risk, it's always a matter of where and how you take trade-offs: you can almost never fix everything, and the influx of vulnerabilities never stops. You never have infinite resources to invest in vulnerabilities remediation, also because that it is not the core business of your company.

So, having an _effective way to prioritize security remediation_ is paramount.

For instance, remediating a severe vulnerability affecting a single asset should not be more urgent than remediating many assets vulnerable to different vulnerability, with a similar severity score.

In the rest of this chapter, we will see three risk metrics, starting with a simple definition and ending with a refined one. As you shall see, perfection is unattainable, still it is worth pursuing the best possible metric we can afford.

### Simple Risk

In its simplest (and often times useless) form, Risk can be quantified as the sum of the product of number of affected assets by the Common Vulnerability Scoring System score ([CVSS, as defined by NIST](https://www.first.org/cvss/user-guide)).

The number of assets affected by a vulnerability represents the _potential attack surface_ for it. The score represents the risk posed by a vulnerability on a single software instance.

More formally, we can define the simple Risk ($sRisk$) for a given vulnerability $v$ in the set of known vulnerabilities $V$ as:

$$ sRisk(v) = |assets(v)| \cdot cvss(v), v \in V $$

Or, if we want to calculate the aggregated risk on all the software we own:

$$ sRisk = \sum\limits_{v \in V} sRisk(v) $$

In both cases, $assets(v)$ is the set of assets (i.e., software instances) affected by the vulnerability $v$, and $cvss(v)$ is the CVSS Score of $v$.

In practical terms, the set of known vulnerabilities is given by the vulnerability scanners used.

### Triaged Risk

In large companies, you don't want to send urgent tickets to your engineers to resolve non-existent vulnerabilities.

Many times, the risk posed by a software vulnerability can be better evaluated considering how that particular software instance is compiled, configured and used.
In other words, _triaging of vulnerabilities_ could improve our understanding of the security risk and help to modulate remediation efforts and investments.

The definition of Risk we gave before does not account for automatic or manual triage. We almost always want to use a risk score enriched with information on the actual usage of software and potential mitigations that are in place.

**Automatic triage**
Automatic triage is what many vulnerability scanners do: they often try to give a better risk score, and reduce the number of false positives, by taking into account the context and how the software is used and the mitigations in place (e.g., AppArmor or SELinux).

For instance, Red Hat provides an [adjusted score for RHEL](https://access.redhat.com/security/updates/classification) (RedHat Enterprise Linux) packages. As you can read in their documentation:

> [...] NVD may rate a flaw in a particular service as having High Impact on the CVSS CIA Triad (Confidentiality, Integrity, Availability) where the service in question is typically run as the root user with full privileges on a system. However, in a Red Hat product, the service may be specifically configured to run as a dedicated non-privileged user running entirely in a SELinux sandbox, greatly reducing the immediate impact from compromise, resulting in Low impact.

Many vendors sell vulnerability feeds with additional and refined information about vulnerabilities. [Snyk](https://snyk.io), [Accenture iDefense](https://www.accenture.com/_acnmedia/pdf-71/accenture-idefense-intelgraph.pdf), [Flexera](https://www.flexera.com), and [FireEye](https://www.fireeye.com) are some example.
You can implement your own automated triage pipeline, using readily available, and open source, tools like [nvdtool](https://github.com/facebookincubator/nvdtools).

**Manual triage**
In environments where there is a high level of "standardization" and customization (i.e. most hyper-scale companies), human triage can be also used.
Security analysts reviews vulnerabilities and manually adjust (up or down) the CVSS score. This is done typically by tweaking the [CVSS vector string](https://www.first.org/cvss/calculator/3.0) according to the context.

To explain this better, let's consider a real-life scenario.
[CVE-2020-12284](https://nvd.nist.gov/vuln/detail/CVE-2020-12284) affects [FFmpg](https://www.ffmpeg.org) 4.1 and 4.2.2, but we know our version is not compiled with anything using `cbs_jpeg_split_fragment` in `libavcodec/cbs_jpeg.c`.
The problem is still there, so it would be nice to have an upgrade, but upgrading FFmpeg is less urgent than mitigating an exploitable vulnerability, so we can "temporarily downgrade" the score.

Vice versa, there could be situations in which we might want to bump up the risk score, because a given software is configured in a way that makes the impacts of an exploit even more dangerous...

**Triaged Risk calculation**
We can define the triaged Risk, $tRisk$, for a vulnerability $v \in V$, as

$$ tRisk(v) = |assets(v)| \cdot tscore(v)$$

Where $tscore(v)$ is the triage score for $v$. This is a function of the CVSS score and any other automatic and manual assessment regarding $v$.

It is also useful to calculate the aggregated triaged Risk on all the assets (e.g., machines). This can be calculated as follows:

$$ tRisk = \sum\limits_{v \in V} tRisk(v) $$

In a realistic scenario, $V$ is the set of vulnerabilities discovered by your scanners, and $tscore(v)$ is the score assigned by the scanner to $v$.

### Enhanced Risk

In more mature vulnerability programs, Risk should consider even more details.

For instance, we may want to take into account:

- Temporal factors - how long the vulnerability has been around?
  - The exploitation of a very old vulnerability, even with minimal quantifiable damage, can give your users the perception that you don't care about security...
- Intelligence data
  - is this vulnerability being actively exploited by [APT](https://en.wikipedia.org/wiki/Advanced_persistent_threat) (Advanced Persistent Threat) against similar companies (see [Operation Aurora](https://en.wikipedia.org/wiki/Operation_Aurora))
  - is our intelligence/red-team aware of exploits?
- Blast radius - is this vulnerability affecting highly-sensitive environments?

We can enrich the previous risk score definition with any additional information, in an automated or manual way. We call this new Risk definition _Enhanced Risk_ ($eRisk$), and calculate it as:

$$ eRisk(v) = escore(v) \cdot \sum\limits_{a \in assets(v)} br(a) \cdot ex(a) $$

So, we can now calculate the aggregated enhanced risk as:

$$ eRisk = \sum\limits_{v \in V} eRisk(v) $$

Where $br(a)$ is the blast radius of $a$, and $ex(a)$ is the exposure of the asset $a$ to threats.

The range of values $br()$ and $ex()$ can take should be devised so that we can effectively "bump up" vulnerabilities remediation priority as needed.
In other words if $eRisk(v') > eRisk(v'')$, remediation of $v'$ should take priority over remediation of $v''$.

Just as an example, we could say that:

$$ \forall a \in assets(v) \quad  br(a) \in [1,1.5] \quad \textrm{and} \quad ex(a) \in [1,1.5] $$

With $br(a) = 1 \ \text{and} \ ex(a) = 1$ if we don't have any reason to bump up or down the "importance" of vulnerabilities affecting the asset $a$.

Finally, $escore(v)$ is the enhanced score for $v$. It should consider aspects that can affect the [CVSS vector string](https://www.first.org/cvss/calculator/3.0), such as:

- manual triage;
- adjusted CVSS score provided by vendors (e.g., RH adjusted score);
- intelligence information such as known exploitation in the wild;
- age of the vulnerability (time elapsed from the time of public or intelligence disclosure).

### Normalizing the Risk

The number of assets grows and shrink frequently in time. And so does the Risk, if new assets are affected by any vulnerability.
This, intuitively, makes sense as our vulnerable surface depends on the number of assets we have, but it makes it hard to track the progress of our vulnerability management program over time.

In many cases, we want to have a definition of Risk based on the _relative_ vulnerable surface (i.e., fraction of affected assets). So, our Risk executive metric needs to be normalized on the number of assets considered in the reference period, $|A|$.
We can define the normalized, triaged, risk as:

$$ ntRisk = \frac{tRisk}{|A|} $$

Where $assets$ is the set of all assets on which we are running the vulnerability management program at time $t$, and $tRisk$ is the triaged risk at time $t$.

In the same way, we can calculate the normalized, enhanced, risk at time $t$ as:

$$ neRisk = \frac{eRisk}{|A|} $$

Note that this definition still _doesn't have an upper bound_, as vulnerability score is a positive number greater or equal to 1.
Effectively we are now calculating the score as follows:

$$ ntRisk = \frac{\sum\limits_{v \in V} |assets(v)| \cdot tscore(v) }{|A|} = \sum\limits_{v \in V} \frac{|assets(v)|}{|A|} \cdot tscore(v) $$

Where $\frac{|assets(v)|}{|A|}$ is the fraction of assets affected by a vulnerability $v$.

Note that $A$ is the set of asset instances. So $|A|$ is the number of software instances installed the reference domain.

The normalized Risk can be used to compare the security posture of different parts of the company, as it doesn't depend on the absolute number of assets.

### Defining what good looks like for Risk

Given the definition of normalized risk above, we can track progress by comparing, for instance, $ntRisk^{t1}$ and $ntRisk^{t2}$.
If $t2 > t1$ and $ntRisk^{t1} > ntRisk^{t2}$, we can say that we are making progress in the right direction.

We can set a target for $ntRisk$, considering anything below it acceptable residual risk.
Or, we can define risk bands: `low, medium, high, critical`. And provide a very high level idea of the risk our company is subject to.

Note that time granularity depends on the frequency vulnerability scanners are run. For very large domains, we could only be able to track progress every couple of days or every week.

As you probably have realized, the quality and freshness of the asset inventory is critical to have a meaningful Risk score.
We will see in the chapter about Coverage that inventories are a typical problem for large companies. You should invest lots of your resources in doing inventory right, before taking any risk score too seriously.

## Coverage

Risk alone can't give the complete picture about the company's security posture.
When it comes to Vulnerability Management it is important to have the risk calculated on as many assets as possible, ideally on all of them.
Not only that. The quality of coverage needs to be good enough to guarantee that at least the most critical vulnerabilities are timely surfaced.

### Inventory Coverage

Inventory Coverage (IC) can be easily calculated as the percentage of assets scanned by vulnerability management tools with respect to the total assets in our inventory.

Again, a good understanding of the company's inventory is a prerequisite for an effective management of vulnerabilities.

In other words, while the coverage of known assets is responsibility of vulnerability management, completeness of inventory is not.
This also makes sense because the inventory of company's assets is generally used for multiple purposes, vulnerability management being only one.

**Using multiple scanners**
In large companies it's not uncommon to have multiple vulnerability scanners working together, typically assessing different environment, but sometimes with some overlap.

Nowadays, many security companies try to provide tools for as many environments as possible, but it's hard to find a single brand covering everything: hosted servers, cloud resources, containers, and network devices, to mention some.

Hyper-scale companies may also want to write their own custom tools, and, if they write software, also add language vulnerability management and static code analysis to the mix.

**Calculate Inventory Coverage**
We can calculate the asset coverage as the percentage of the assets we cover with at least one type of scanner. We can call this metric Inventory Coverage (IC).

$$ iCoverage^t = \frac{|SA^t|}{|IA^t|} \quad \text{with} \ SA^t \subseteq IA^t$$

$SA^t$ is the set of Scanned Assets, at time $t$, while $IA$ is the Inventory of company's Assets at the same reference time $t$.

### Coverage Confidence

When the vulnerability management landscape is large and complex, and custom tooling is used, we need to understand how well we are covering each domain.
If we assume that as long as at least one security scanner analyses a resource, "we are covered", may create a dangerous false sense of security.

To refine our understanding of our posture, we can introduce a measure of confidence in the coverage, that we can call Coverage Confidence ($cConfidence$).

The Inventory Coverage metric we saw before is still needed, for instance for compliance purposes, but we can introduce the Scan Coverage formula to account for the quality of scanning for each asset type.

To calculate the Coverage Confidence, we multiply the number of unique assets scanned in a given category by a _confidence factor_ given by how much we trust the information collected.
This confidence value reflects the capabilities, and the known limitations, of the specific security assessment tool used for each type of asset.

One way is to consider how we the scan is performed relative to the type of asset at hand.
For instance, we may have a very good confidence that our agent-based solution works great for Windows Servers. Whereas, if we use a network scanner for our Linux fleet, it's likely it won't surface many vulnerabilities on installed packages not running exposed services.

The Coverage Confidence metric can be calculated as:

$$ cConfidence^t = \frac{\sum\limits_{c \in SC} \theta_{c} \cdot |SA_{c}^t|}{|IA^t|} $$

Where $\theta_c \in (0,1]$ is the confidence we have in our scanning capability for the asset/scan category $c$.

$SC$ is the set of scan categories we can identify in our environment. For instance, if we have two scanners, a network and an agent based, $SC$ will contain these two elements.
$SA_{c}^t$ is the set of assets covered with scanning methodology $c$, at time $t$.

Note that we are assuming that different scanning methodologies cover different assets. If there are overlap for some assets, we can pick $SC$ to consider the superposition of two or more scanning methodologies. E.g.:

$$ SC = \{ \text{network and agent}, \text{only agent}, \text{only network} \} $$

### Defining what good looks like for Coverage

For the Coverage metric, the goal is to bring the value of $iCoverage$ and/or $cConfidence$ as close as possible to 1, by improving the asset coverage and the quality of scans.

We can measure progress on Coverage by looking at the difference between values of $iCoverage$ and/or $cConfidence$ registered at different, moment in time.

# Operational Metrics

Up to this point we have only been talking about Risk and Coverage, framing them as Executive or first order metrics.

Executive metrics will give us a synthetic view on how the Vulnerability Management program is going, but won't tell clearly how and where we can improve to make it better.

Establishing operational metrics, and _Service Level Objective_ (SLO) on them, is an effective way we can use in large companies to influence _**how**_ executive metrics should be driven down.

Without any claim to be exhaustive, in this section I will mention some of the metrics that have been used successfully on large-scale vulnerability management.

## Remediation Timeliness

### Average Vulnerabilities Age

### Time To Manage

### Defining what good looks like for Remediation Timeliness


## Remediation queue size

## Assets freshness
